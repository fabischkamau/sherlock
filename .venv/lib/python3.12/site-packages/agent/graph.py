from arango import ArangoClient
from langchain_community.graphs import ArangoGraph
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
import os
from langgraph.graph import MessagesState, StateGraph, START, END
from pydantic import BaseModel
from langchain_core.tools import tool
from langchain_core.messages import ToolMessage
from langgraph.types import Command
from typing_extensions import Literal
from langgraph.checkpoint.memory import MemorySaver
import re
from typing import List, Union, Optional, Dict, Any
from pydantic import BaseModel, Field 
from typing import Any
from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain
import networkx as nx
import nx_arangodb as nxadb
import dotenv

dotenv.load_dotenv()

os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_ENDPOINT"] = "https://api.smith.langchain.com"
os.environ["LANGSMITH_PROJECT"] = "SHERLOCK"




client = ArangoClient(hosts="http://localhost:8529")
db = client.db("_system", username="root", password="openSesame")
arango_graph = ArangoGraph(db)

model = ChatAnthropic(model="claude-3-7-sonnet-latest")
G_adb = nxadb.MultiGraph(name="CrimeKnowledgeGraph", db=db, default_node_type=None)

@tool
def transfer_to_profiling_expert():
  """Ask Profiling agent for help
      - Analyzes demographic and behavioral patterns
      - Creates suspect/victim profiles based on historical data
      - Identifies recurring patterns in criminal activity
  """  
  return

@tool
def transfer_to_reporting_expert():
  """Ask reporting Agent for Help
      - Summarizes findings in structured reports
  """
  return

@tool
def tranfer_to_network_analysis_expert():
  """Ask Network Analysis for report
      - Specializes in identifying patterns and connections using NetworkX Algorithms
  """
@tool 
def transfer_to_network_visualization():
  """ Use this tool to visualize network provide sample question to fetch subgraph and visualize""
  """
  return

supervisor_tools=[transfer_to_profiling_expert,tranfer_to_network_analysis_expert]




class NodeData(BaseModel):
    id: int = Field(description="unique id of the node")
    label: str = Field(description="label of the node")
    name: str = Field(description="name of the node to be displayed in the visialization")
    content: Optional[str] = None


class Node(BaseModel):
    data: NodeData = Field(description="data of the node")


class EdgeData(BaseModel):
    id: int = Field(description="unique id of the edge")
    label: str = Field(description="label of the edge")
    source: int  = Field(description="source node id")
    target: int = Field(description="target node id")


class Edge(BaseModel):
    data: EdgeData = Field(description="data of the edge")


class GraphElements(BaseModel): 
    nodes: List[Node]
    edges: List[Edge]

def supervisor(state: MessagesState) ->Command[Literal["network_expert", "profile_expert", "reporting_expert","__end__"]]:
    system_prompt = (
        """
        You are a coordinator expert for crime reporting tool called SHERLOCK ( Strategic Heuristic Engine for Research, Linking & Operational Crime Knowledge )
        Your task is to handle handoffs to various experts to answer user questions. If question is out of domain let the user know what you can do for them and do not mention you are coodinator or supervisor. Let you answer be precise.
        """
    )

    messages = [{"role": "system", "content": system_prompt}] + state["messages"]

    ai_msg = model.bind_tools(supervisor_tools).invoke(messages)


    if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get("name") == "transfer_to_profiling_expert":
        tool_call_id = ai_msg.tool_calls[-1]["id"]
        tool_msg = {
            "role": "tool",
            "content": "Successfully transferred",
            "tool_call_id": tool_call_id,
        }

        return Command(
            goto="profile_expert", update={"messages": [ai_msg, tool_msg]}
        )

    if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get("name") == "tranfer_to_network_analysis_expert":
        tool_call_id = ai_msg.tool_calls[-1]["id"]

        tool_msg = {
            "role": "tool",
            "content": "Successfully transferred",
            "tool_call_id": tool_call_id,
        }

        return Command(
            goto="network_expert", update={"messages": [ai_msg, tool_msg]}
        )

    if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get("name") == "transfer_to_reporting_expert":
        tool_call_id = ai_msg.tool_calls[-1]["id"]

        tool_msg = {
            "role": "tool",
            "content": "Successfully transferred",
            "tool_call_id": tool_call_id,
        }

        return Command(
            goto="reporting_expert", update={"messages": [ai_msg, tool_msg]}
        )

    return {"messages": [ai_msg]}

@tool
def text_to_nx_algorithm_to_text(query):
    """This tool is available to invoke a NetworkX Algorithm on
    the ArangoDB Graph. You are responsible for accepting the
    Natural Language Query, establishing which algorithm needs to
    be executed, executing the algorithm, and translating the results back
    to Natural Language, with respect to the original query.

    If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use
    this tool.
    """

    llm = ChatOpenAI(temperature=0, model_name="gpt-4o")

    ######################
    print("1) Generating NetworkX code")

    text_to_nx = llm.invoke(f"""
    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}

    I have the following graph analysis query: {query}.

    Generate the Python Code required to answer the query using the `G_adb` object.

    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.

    Only assume that networkx is installed, and other base python dependencies.

    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.

    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.

    Make sure that `FINAL_RESULT` stores a short & consice answer. Avoid setting this variable to a long sequence.

    Your code:
    """).content

    text_to_nx_cleaned = re.sub(r"^```python\n|```$", "", text_to_nx, flags=re.MULTILINE).strip()

    print('-'*10)
    print(text_to_nx_cleaned)
    print('-'*10)

    ######################

    print("\n2) Executing NetworkX code")
    global_vars = {"G_adb": G_adb, "nx": nx}
    local_vars = {}

    attempt = 1
    MAX_ATTEMPTS = 3
    text_to_nx_final = text_to_nx_cleaned
    
    while attempt <= MAX_ATTEMPTS:
        try:
            exec(text_to_nx_final, global_vars, local_vars)
            print(f"Successfully executed on attempt {attempt}")
            break  # Success, exit the loop
        except Exception as e:
            error_message = str(e)
            print(f"EXEC ERROR (Attempt {attempt}/{MAX_ATTEMPTS}): {error_message}")
            
            if attempt == MAX_ATTEMPTS:
                return f"Failed after {MAX_ATTEMPTS} attempts. Last error: {error_message}"
            
            # Try to fix the code with LLM
            print(f"Attempting to fix code (Attempt {attempt}/{MAX_ATTEMPTS})")
            
            correction_prompt = f"""
            I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}

            I have the following graph analysis query: {query}.
            
            I tried to execute the following Python code to analyze a NetworkX graph G_adb:
            
            ```python
            {text_to_nx_final}
            ```
            
            But I got this error: {error_message}
            
            Please fix the code. Remember:
            1. The graph is called G_adb
            2. Only use networkx (as nx) and base Python libraries
            3. The final answer should be stored in a variable called FINAL_RESULT
            4. Only provide executable Python code, no explanations
            
            Your corrected code:
            """
            
            try:
                fixed_code_response = llm.invoke(correction_prompt).content
                # Clean up the response in case it returns markdown code blocks
                text_to_nx_final = re.sub(r"^```python\n|```$", "", fixed_code_response, flags=re.MULTILINE).strip()
                
                print('-'*10)
                print("FIXED CODE ATTEMPT:")
                print(text_to_nx_final)
                print('-'*10)
            except Exception as llm_error:
                print(f"Error requesting code correction: {llm_error}")
                return f"Failed to get code correction: {llm_error}"
            
            attempt += 1
    
    # If we exited the loop without a successful execution
    if attempt > MAX_ATTEMPTS:
        return f"All {MAX_ATTEMPTS} attempts failed. Could not execute the NetworkX algorithm."
    
    print('-'*10)
    if "FINAL_RESULT" not in local_vars:
        return "Execution succeeded but FINAL_RESULT variable was not set."
        
    FINAL_RESULT = local_vars["FINAL_RESULT"]
    print(f"FINAL_RESULT: {FINAL_RESULT}")
    print('-'*10)

    ######################

    print("3) Formulating final answer")

    nx_to_text = llm.invoke(f"""
        I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}

        I have the following graph analysis query: {query}.

        I have executed the following python code to help me answer my query:

        ---
        {text_to_nx_final}
        ---

        The `FINAL_RESULT` variable is set to the following: {FINAL_RESULT}.

        Based on my original Query and FINAL_RESULT, generate a short and concise response to
        answer my query.

        Your response:
    """).content

    return nx_to_text

network_tools = [text_to_nx_algorithm_to_text,transfer_to_profiling_expert, transfer_to_reporting_expert]


def network_expert(state:MessagesState)->Command[Literal["profile_expert", "reporting_expert","network_expert", "visualize_network","__end__"]]:
    system_prompt = (
        """
        You expert for crime reporting tool called SHERLOCK ( Strategic Heuristic Engine for Research, Linking & Operational Crime Knowledge )
        Your task is to Analyze networks using the text_to_nx_algorithm_to_text tool and if question reequires futher analysis transfer. When necessary to view subgraph of the data tranfer to visualize_network after analysis.

        """
    )

    messages = [{"role": "system", "content": system_prompt}] + state["messages"]

    ai_msg = model.bind_tools(network_tools).invoke(messages)

    if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get("name") == "transfer_to_profiling_expert":
        tool_call_id = ai_msg.tool_calls[-1]["id"]
        tool_msg = {
            "role": "tool",
            "content": "Successfully transferred",
            "tool_call_id": tool_call_id,
        }

        return Command(
            goto="profile_expert", update={"messages": [ai_msg, tool_msg]}
        )


    if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get("name") == "transfer_to_reporting_expert":
        tool_call_id = ai_msg.tool_calls[-1]["id"]

        tool_msg = {
            "role": "tool",
            "content": "Successfully transferred",
            "tool_call_id": tool_call_id,
        }

        return Command(
            goto="reporting_expert", update={"messages": [ai_msg, tool_msg]}
        )

    if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get("name") == "text_to_nx_algorithm_to_text":
        tool_call_id = ai_msg.tool_calls[-1]["id"]

        content = text_to_nx_algorithm_to_text(ai_msg.tool_calls[-1].get("args").get("query"))
        tool_msg = {
            "role": "tool",
            "content": content,
            "tool_call_id": tool_call_id,
        }

        return Command(
            goto="network_expert", update={"messages":[ai_msg, tool_msg]}
        )

    if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get("name") == "transfer_to_network_visualization":
        tool_call_id = ai_msg.tool_calls[-1]["id"]
        tool_msg = {
            "role": "tool",
            "content": "Successfully transferred",
            "tool_call_id": tool_call_id,
        }
        return Command(
            goto="visualize_network", update={"messages": [ai_msg, tool_msg]}
        )

    return {"messages": [ai_msg]}



@tool
def text_to_aql_to_text(query: str):
    """This tool is available to invoke the
    ArangoGraphQAChain object, which enables you to
    translate a Natural Language Query into AQL, execute
    the query, and translate the result back into Natural Language.
    """

    llm = ChatOpenAI(temperature=0, model_name="gpt-4o")

    chain = ArangoGraphQAChain.from_llm(
    	llm=llm,
    	graph=arango_graph,
    	verbose=True,
      allow_dangerous_requests=True,
      return_aql_query=True
    )

    result = chain.invoke(query)

    return str(result["result"])

profile_expert_tools = [text_to_aql_to_text, transfer_to_reporting_expert]



def profile_expert(state:MessagesState)->Command[Literal["profile_expert","reporting_expert", "visualize_network","__end__"]]:
  system_prompt = (
      f"""
        You are an expert for crime reporting tool called SHERLOCK ( Strategic Heuristic Engine for Research, Linking & Operational Crime Knowledge )
        Your task is to the arango database use arango database to analyze and answer questions about crime using the tools provided and transfer when neccesary.
        When necessary to view subgraph of the data tranfer to visualize_network after analysis.

      """
  )

  ai_msg = model.bind_tools(profile_expert_tools).invoke([{"role":"system", "content":system_prompt}]+state["messages"])

  if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get("name") == "transfer_to_reporting_expert":
      tool_call_id = ai_msg.tool_calls[-1]["id"]
      tool_msg = {
          "role": "tool",
          "content": "Successfully transferred",
          "tool_call_id": tool_call_id,
      }
      return Command(
          goto="reporting_expert", update={"messages": [ai_msg, tool_msg]}
      )

  if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get("name") == "text_to_aql_to_text":
      tool_call_id = ai_msg.tool_calls[-1]["id"]
      content = text_to_aql_to_text(ai_msg.tool_calls[-1].get("args").get("query"))
      tool_msg = {
          "role": "tool",
          "content": content,
          "tool_call_id": tool_call_id,
      }

      return Command(
          goto="profile_expert", update={"messages":[ai_msg, tool_msg]}
      )

  if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get("name") == "transfer_to_network_visualization":
      tool_call_id = ai_msg.tool_calls[-1]["id"]
      tool_msg = {
          "role": "tool",
          "content": "Successfully transferred",
          "tool_call_id": tool_call_id,
      }
      return Command(
          goto="visualize_network", update={"messages": [ai_msg, tool_msg]}
      )

  return {"messages":state["messages"]+ [{"role":"ai", "content":ai_msg.content}]}
def reporting_expert(state:MessagesState)->Command[Literal["__end__"]]:

  system_prompt = (
      """
        You are an expert in  crime reporting. Analyze our conversations and do a comprehensive report.

        Here is the conversation so far:
      """
  )

  messages = [{"role": "system", "content": system_prompt}] + state["messages"]

  ai_msg = model.invoke(messages)
  return {"messages": [ai_msg]}



def visualize_graph(state:MessagesState)->Command[Literal["__end__"]]:

  system_prompt = (
      f"""
        You are an expert creating AQL query that follows a specific format for returning results for visualization later.

        Here is the arango schema {arango_graph.schema}
        Alway follow the format for the return query: {GraphElements}
      
      Guidelines for creating AQL:
        - Think step by step
        - Analyze user question and determine the best AQL query to answer the question.
        - Rely on `ArangoDB Schema` and `AQL Query Examples` (if provided) to generate the query
        - Rely on `ArangoDB Schema` and `AQL Query Examples` (if provided) to generate the query
        - Begin the `AQL Query` by the `WITH` AQL keyword to specify all of the ArangoDB Collections required
        - Use only the provided relationship types and properties in the `ArangoDB Schema` and any `AQL Query Examples` queries
        - Always use the `LIKE` operator for string matching
        - Structure the return value of the AQL Query in the a way that is easy to read and understand and answer the user's question  ,
        - Identify nodes and edges that might be relevant to the  question and include them in the AQL Query.
        
        Your query:
      """
  )

  ai_msg = model.invoke([{"role":"system", "content":system_prompt}]+state["messages"])

  result = arango_graph.query(ai_msg.content)
  data = GraphElements(nodes=result["nodes"], edges=result["edges"])
  return {"visualization_data": visualize_graph}

class State(MessagesState):
  visualization_data:GraphElements

workflow = StateGraph(State)


workflow.add_node("supervisor", supervisor)
workflow.add_node("network_expert", network_expert)
workflow.add_node("profile_expert", profile_expert)
workflow.add_node("reporting_expert", reporting_expert)
workflow.add_node("visualize_network", visualize_graph)

workflow.add_edge(START, "supervisor")

checkpointer=MemorySaver()

agent = workflow.compile(checkpointer=checkpointer)

graph.name="SHERLOCK"
