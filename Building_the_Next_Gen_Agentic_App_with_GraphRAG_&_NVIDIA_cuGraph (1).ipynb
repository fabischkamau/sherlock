{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "998aa417153340928e3a6a8fa608ca3c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_33f898f71c9b4701895a09db49141de0",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "(NX → ADB): Nodes \u001b[38;2;151;196;35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m (102392/102392) \u001b[33m0:00:00\u001b[0m\n     ADB Import: 'Weapon' (12) \u001b[38;2;91;192;222m▰▰▰▰▰▰▱\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">(NX → ADB): Nodes <span style=\"color: #97c423; text-decoration-color: #97c423\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> (102392/102392) <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span>\n     ADB Import: 'Weapon' (12) <span style=\"color: #5bc0de; text-decoration-color: #5bc0de\">▰▰▰▰▰▰▱</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "33f898f71c9b4701895a09db49141de0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc3845418f284447a8a4ee1d9626cb04": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_a21f76ef453a4f67bf396b23a579277f",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "(NX → ADB): Edges \u001b[38;2;94;49;8m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m (321951/321951) \u001b[33m0:00:01\u001b[0m\n     ADB Import: 'PART_OF' (45993) \u001b[38;2;91;192;222m▰▰▰▰▰▰▱\u001b[0m \u001b[33m0:00:05\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">(NX → ADB): Edges <span style=\"color: #5e3108; text-decoration-color: #5e3108\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> (321951/321951) <span style=\"color: #808000; text-decoration-color: #808000\">0:00:01</span>\n     ADB Import: 'PART_OF' (45993) <span style=\"color: #5bc0de; text-decoration-color: #5bc0de\">▰▰▰▰▰▰▱</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:05</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "a21f76ef453a4f67bf396b23a579277f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze-VPtUJr0EA",
        "outputId": "c5aef098-99e4-4284-f164-8e8c04431296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q nx-arangodb networkx adbnx_adapter pyvis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q nx-cugraph-cu12 --extra-index-url https://pypi.nvidia.com"
      ],
      "metadata": {
        "id": "9x7qllgMuWPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from arango import ArangoClient\n",
        "from adbnx_adapter import ADBNX_Adapter, ADBNX_Controller\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "jQ-cgcHn47s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_crime_data(csv_file_path):\n",
        "    \"\"\"Load and preprocess crime data from a CSV file.\"\"\"\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "    df.columns = [col.strip() for col in df.columns]  # Clean column names\n",
        "    return df.fillna('Unknown')  # Handle missing values\n",
        "\n",
        "def create_knowledge_graph(df):\n",
        "    \"\"\"Create a MultiDiGraph from crime data with enhanced relationships.\"\"\"\n",
        "    G = nx.MultiDiGraph()\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        # Create unique IDs for each entity\n",
        "        crime_id = f\"Crime_{row['RowID']}\"\n",
        "        location_id = f\"Location_{row['Location'].replace(' ', '_')}\"\n",
        "        crime_type_id = f\"CrimeType_{row['CrimeCode']}\"\n",
        "        person_id = f\"Person_{row['RowID']}\"  # Using RowID to make unique persons\n",
        "        weapon_id = f\"Weapon_{row['Weapon']}\" if row['Weapon'] else None\n",
        "        neighborhood_id = f\"Neighborhood_{row['Neighborhood']}\" if row['Neighborhood'] else \"Neighborhood_Unknown\"\n",
        "        district_id = f\"District_{row['New_District']}\" if row['New_District'] else \"District_Unknown\"\n",
        "        premise_id = f\"Premise_{row['PremiseType'].strip()}\" if row['PremiseType'] else \"Premise_Unknown\"\n",
        "\n",
        "        # Parse datetime\n",
        "        crime_datetime = row['CrimeDateTime']\n",
        "        try:\n",
        "            dt_obj = datetime.strptime(crime_datetime, \"%m/%d/%Y %I:%M:%S %p\")\n",
        "            hour_of_day = dt_obj.hour\n",
        "            day_of_week = dt_obj.strftime('%A')\n",
        "            month = dt_obj.strftime('%B')\n",
        "            year = dt_obj.year\n",
        "        except (ValueError, TypeError):\n",
        "            hour_of_day = None\n",
        "            day_of_week = None\n",
        "            month = None\n",
        "            year = None\n",
        "\n",
        "        # Add nodes with attributes\n",
        "        G.add_node(crime_id, type='Crime', datetime=crime_datetime, hour_of_day=hour_of_day, day_of_week=day_of_week, month=month, year=year)\n",
        "        G.add_node(location_id, type='Location', latitude=row['Latitude'], longitude=row['Longitude'])\n",
        "        G.add_node(crime_type_id, type='CrimeType', code=row['CrimeCode'], description=row['Description'])\n",
        "        G.add_node(person_id, type='Person', gender=row['Gender'], age=row['Age'], race=row['Race'], ethnicity=row['Ethnicity'])\n",
        "        G.add_node(neighborhood_id, type='Neighborhood', name=row['Neighborhood'])\n",
        "        G.add_node(district_id, type='District', name=row['New_District'])\n",
        "        G.add_node(premise_id, type='PremiseType', name=row['PremiseType'])\n",
        "\n",
        "        if weapon_id:\n",
        "            G.add_node(weapon_id, type='Weapon', name=row['Weapon'])\n",
        "            G.add_edge(crime_id, weapon_id, relationship='USED')\n",
        "\n",
        "        # Add edges with relationship types\n",
        "        G.add_edge(crime_id, location_id, relationship='OCCURRED_AT')\n",
        "        G.add_edge(crime_id, crime_type_id, relationship='CLASSIFIED_AS')\n",
        "        G.add_edge(crime_id, person_id, relationship='INVOLVED')\n",
        "        G.add_edge(location_id, neighborhood_id, relationship='LOCATED_IN')\n",
        "        G.add_edge(neighborhood_id, district_id, relationship='PART_OF')\n",
        "        G.add_edge(crime_id, premise_id, relationship='OCCURRED_IN')\n",
        "\n",
        "    print(f\"Created knowledge graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
        "    return G\n",
        "\n",
        "class CrimeGraphController(ADBNX_Controller):\n",
        "    \"\"\"Custom controller for crime graph translation.\"\"\"\n",
        "    def _identify_networkx_node(self, nx_node_id, nx_node, adb_v_cols):\n",
        "        \"\"\"Map NetworkX nodes to ArangoDB collections based on type.\"\"\"\n",
        "        return nx_node.get('type', 'Unknown')\n",
        "\n",
        "    def _identify_networkx_edge(self, nx_edge, from_id, to_id, nx_map, adb_e_cols):\n",
        "        \"\"\"Map NetworkX edges to ArangoDB collections based on relationship.\"\"\"\n",
        "        return nx_edge.get('relationship', 'RELATED_TO')"
      ],
      "metadata": {
        "id": "RYcNj0PM5Az2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Load data and create graph\n",
        "    df = load_crime_data(\"NIBRS.csv\")\n",
        "    nx_graph = create_knowledge_graph(df)\n",
        "\n",
        "    # ArangoDB connection\n",
        "    client = ArangoClient(hosts=\"https://d6b0bbc5c6ad.arangodb.cloud:8529\")\n",
        "    db = client.db(\"_system\", username=\"root\", password=\"cnA4t2mc33IS5LiC0YJI\")\n",
        "\n",
        "    # Define edge collections based on relationship types\n",
        "    edge_definitions = [\n",
        "        {\"edge_collection\": \"OCCURRED_AT\", \"from_vertex_collections\": [\"Crime\"], \"to_vertex_collections\": [\"Location\"]},\n",
        "        {\"edge_collection\": \"CLASSIFIED_AS\", \"from_vertex_collections\": [\"Crime\"], \"to_vertex_collections\": [\"CrimeType\"]},\n",
        "        {\"edge_collection\": \"INVOLVED\", \"from_vertex_collections\": [\"Crime\"], \"to_vertex_collections\": [\"Person\"]},\n",
        "        {\"edge_collection\": \"LOCATED_IN\", \"from_vertex_collections\": [\"Location\"], \"to_vertex_collections\": [\"Neighborhood\"]},\n",
        "        {\"edge_collection\": \"PART_OF\", \"from_vertex_collections\": [\"Neighborhood\"], \"to_vertex_collections\": [\"District\"]},\n",
        "        {\"edge_collection\": \"OCCURRED_IN\", \"from_vertex_collections\": [\"Crime\"], \"to_vertex_collections\": [\"PremiseType\"]},\n",
        "        {\"edge_collection\": \"USED\", \"from_vertex_collections\": [\"Crime\"], \"to_vertex_collections\": [\"Weapon\"]},\n",
        "    ]\n",
        "\n",
        "    # Create adapter and load to ArangoDB\n",
        "    adapter = ADBNX_Adapter(db, CrimeGraphController())\n",
        "    adapter.networkx_to_arangodb(\n",
        "        \"CrimeKnowledgeGraph\",\n",
        "        nx_graph,\n",
        "        edge_definitions=edge_definitions,\n",
        "        overwrite=True\n",
        "    )\n",
        "    print(\"Crime knowledge graph successfully loaded into ArangoDB.\")"
      ],
      "metadata": {
        "id": "hK21ZUdz5PsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "998aa417153340928e3a6a8fa608ca3c",
            "33f898f71c9b4701895a09db49141de0",
            "dc3845418f284447a8a4ee1d9626cb04",
            "a21f76ef453a4f67bf396b23a579277f"
          ]
        },
        "id": "y4NKq5Jc5Z7i",
        "outputId": "6b656e41-207a-4fac-e391-573617c6bc6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-f1e649f9400c>:3: DtypeWarning: Columns (8,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(csv_file_path)\n",
            "[2025/03/07 11:08:39 +0000] [1111] [INFO] - adbnx_adapter: Instantiated ADBNX_Adapter with database '_system'\n",
            "INFO:adbnx_adapter:Instantiated ADBNX_Adapter with database '_system'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created knowledge graph with 102392 nodes and 321951 edges\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "998aa417153340928e3a6a8fa608ca3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc3845418f284447a8a4ee1d9626cb04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025/03/07 11:09:19 +0000] [1111] [INFO] - adbnx_adapter: Created ArangoDB 'CrimeKnowledgeGraph' Graph\n",
            "INFO:adbnx_adapter:Created ArangoDB 'CrimeKnowledgeGraph' Graph\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crime knowledge graph successfully loaded into ArangoDB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nx_arangodb as nxadb\n",
        "from arango import ArangoClient"
      ],
      "metadata": {
        "id": "NeA9WMtm-Ps0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c159872-f714-41bf-ece2-a00cf0d9d3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[03:07:19 +0000] [INFO]: NetworkX-cuGraph is available.\n",
            "INFO:nx_arangodb:NetworkX-cuGraph is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = ArangoClient(hosts=\"https://d6b0bbc5c6ad.arangodb.cloud:8529\").db(username=\"root\", password=\"cnA4t2mc33IS5LiC0YJI\", verify=True)\n",
        "\n",
        "print(db)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dLXp7KA8geK",
        "outputId": "14dbe408-b41c-41ca-b357-4129030455c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<StandardDatabase _system>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G_adb = nxadb.MultiGraph(name=\"CrimeKnowledgeGraph\", db=db, default_node_type=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtKxXewE8TdC",
        "outputId": "3a8a00b2-0e0c-4e93-f6df-d234f3979fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[03:07:20 +0000] [INFO]: Graph 'CrimeKnowledgeGraph' exists.\n",
            "INFO:nx_arangodb:Graph 'CrimeKnowledgeGraph' exists.\n",
            "[03:07:20 +0000] [INFO]: Default node type set to 'Crime'\n",
            "INFO:nx_arangodb:Default node type set to 'Crime'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langgraph langchain_openai langchain_anthropic langchain_community"
      ],
      "metadata": {
        "id": "aJmwUCLP9Pt7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4309952e-e01d-47e3-c136-1c20dd82ba3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/131.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.4/415.4 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.graphs import ArangoGraph\n",
        "\n",
        "arango_graph = ArangoGraph(db)"
      ],
      "metadata": {
        "id": "xtWvIb_pCUQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get('ANTHROPIC_API_KEY')\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = userdata.get('LANGSMITH_API_KEY')\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"SHERLOCK\""
      ],
      "metadata": {
        "id": "_IWqs3hT9nUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatAnthropic(model=\"claude-3-7-sonnet-latest\")"
      ],
      "metadata": {
        "id": "OuyY--WF4B9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import MessagesState, StateGraph, START, END\n",
        "from pydantic import BaseModel\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import ToolMessage\n",
        "from langgraph.types import Command\n",
        "from typing_extensions import Literal\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "import re"
      ],
      "metadata": {
        "id": "3nS8knOD4Vzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def transfer_to_profiling_expert():\n",
        "  \"\"\"Ask Profiling agent for help\n",
        "      - Analyzes demographic and behavioral patterns\n",
        "      - Creates suspect/victim profiles based on historical data\n",
        "      - Identifies recurring patterns in criminal activity\n",
        "  \"\"\"\n",
        "  return\n",
        "\n",
        "@tool\n",
        "def transfer_to_reporting_expert():\n",
        "  \"\"\"Ask reporting Agent for Help\n",
        "      - Summarizes findings in structured reports\n",
        "  \"\"\"\n",
        "  return\n",
        "\n",
        "@tool\n",
        "def tranfer_to_network_analysis_expert():\n",
        "  \"\"\"Ask Network Analysis for report\n",
        "      - Specializes in identifying patterns and connections using NetworkX Algorithms\n",
        "  \"\"\"\n",
        "@tool\n",
        "def transfer_to_network_visualization():\n",
        "  \"\"\" Use this tool to visualize network provide sample question to fetch subgraph and visualize\"\"\n",
        "  \"\"\"\n",
        "  return\n",
        "\n",
        "supervisor_tools=[transfer_to_profiling_expert,tranfer_to_network_analysis_expert]"
      ],
      "metadata": {
        "id": "li3uqy--4j3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Union, Optional, Dict, Any\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class NodeData(BaseModel):\n",
        "    id: int = Field(description=\"unique id of the node\")\n",
        "    label: str = Field(description=\"label of the node\")\n",
        "    name: str = Field(description=\"name of the node to be displayed in the visialization\")\n",
        "    content: Optional[str] = None\n",
        "\n",
        "\n",
        "class Node(BaseModel):\n",
        "    data: NodeData = Field(description=\"data of the node\")\n",
        "\n",
        "\n",
        "class EdgeData(BaseModel):\n",
        "    id: int = Field(description=\"unique id of the edge\")\n",
        "    label: str = Field(description=\"label of the edge\")\n",
        "    source: int  = Field(description=\"source node id\")\n",
        "    target: int = Field(description=\"target node id\")\n",
        "\n",
        "\n",
        "class Edge(BaseModel):\n",
        "    data: EdgeData = Field(description=\"data of the edge\")\n",
        "\n",
        "\n",
        "class GraphElements(BaseModel):\n",
        "    nodes: List[Node]\n",
        "    edges: List[Edge]"
      ],
      "metadata": {
        "id": "trnDOo6ioDNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def supervisor(state: MessagesState) ->Command[Literal[\"network_expert\", \"profile_expert\", \"reporting_expert\",\"__end__\"]]:\n",
        "    system_prompt = (\n",
        "        \"\"\"\n",
        "        You are a coordinator expert for crime reporting tool called SHERLOCK ( Strategic Heuristic Engine for Research, Linking & Operational Crime Knowledge )\n",
        "        Your task is to handle handoffs to various experts to answer user questions. If question is out of domain let the user know what you can do for them and do not mention you are coodinator or supervisor. Let you answer be precise.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
        "\n",
        "    ai_msg = model.bind_tools(supervisor_tools).invoke(messages)\n",
        "\n",
        "\n",
        "    if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get(\"name\") == \"transfer_to_profiling_expert\":\n",
        "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
        "        tool_msg = {\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": \"Successfully transferred\",\n",
        "            \"tool_call_id\": tool_call_id,\n",
        "        }\n",
        "\n",
        "        return Command(\n",
        "            goto=\"profile_expert\", update={\"messages\": [ai_msg, tool_msg]}\n",
        "        )\n",
        "\n",
        "    if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get(\"name\") == \"tranfer_to_network_analysis_expert\":\n",
        "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
        "\n",
        "        tool_msg = {\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": \"Successfully transferred\",\n",
        "            \"tool_call_id\": tool_call_id,\n",
        "        }\n",
        "\n",
        "        return Command(\n",
        "            goto=\"network_expert\", update={\"messages\": [ai_msg, tool_msg]}\n",
        "        )\n",
        "\n",
        "    if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get(\"name\") == \"transfer_to_reporting_expert\":\n",
        "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
        "\n",
        "        tool_msg = {\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": \"Successfully transferred\",\n",
        "            \"tool_call_id\": tool_call_id,\n",
        "        }\n",
        "\n",
        "        return Command(\n",
        "            goto=\"reporting_expert\", update={\"messages\": [ai_msg, tool_msg]}\n",
        "        )\n",
        "\n",
        "    return {\"messages\": [ai_msg]}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xt0sQ8zy6_O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def text_to_nx_algorithm_to_text(query):\n",
        "    \"\"\"This tool is available to invoke a NetworkX Algorithm on\n",
        "    the ArangoDB Graph. You are responsible for accepting the\n",
        "    Natural Language Query, establishing which algorithm needs to\n",
        "    be executed, executing the algorithm, and translating the results back\n",
        "    to Natural Language, with respect to the original query.\n",
        "\n",
        "    If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use\n",
        "    this tool.\n",
        "    \"\"\"\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "    ######################\n",
        "    print(\"1) Generating NetworkX code\")\n",
        "\n",
        "    text_to_nx = llm.invoke(f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "    I have the following graph analysis query: {query}.\n",
        "\n",
        "    Generate the Python Code required to answer the query using the `G_adb` object.\n",
        "\n",
        "    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
        "\n",
        "    Only assume that networkx is installed, and other base python dependencies.\n",
        "\n",
        "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
        "\n",
        "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
        "\n",
        "    Make sure that `FINAL_RESULT` stores a short & consice answer. Avoid setting this variable to a long sequence.\n",
        "\n",
        "    Your code:\n",
        "    \"\"\").content\n",
        "\n",
        "    text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
        "\n",
        "    print('-'*10)\n",
        "    print(text_to_nx_cleaned)\n",
        "    print('-'*10)\n",
        "\n",
        "    ######################\n",
        "\n",
        "    print(\"\\n2) Executing NetworkX code\")\n",
        "    global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n",
        "    local_vars = {}\n",
        "\n",
        "    attempt = 1\n",
        "    MAX_ATTEMPTS = 3\n",
        "    text_to_nx_final = text_to_nx_cleaned\n",
        "\n",
        "    while attempt <= MAX_ATTEMPTS:\n",
        "        try:\n",
        "            exec(text_to_nx_final, global_vars, local_vars)\n",
        "            print(f\"Successfully executed on attempt {attempt}\")\n",
        "            break  # Success, exit the loop\n",
        "        except Exception as e:\n",
        "            error_message = str(e)\n",
        "            print(f\"EXEC ERROR (Attempt {attempt}/{MAX_ATTEMPTS}): {error_message}\")\n",
        "\n",
        "            if attempt == MAX_ATTEMPTS:\n",
        "                return f\"Failed after {MAX_ATTEMPTS} attempts. Last error: {error_message}\"\n",
        "\n",
        "            # Try to fix the code with LLM\n",
        "            print(f\"Attempting to fix code (Attempt {attempt}/{MAX_ATTEMPTS})\")\n",
        "\n",
        "            correction_prompt = f\"\"\"\n",
        "            I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "            I have the following graph analysis query: {query}.\n",
        "\n",
        "            I tried to execute the following Python code to analyze a NetworkX graph G_adb:\n",
        "\n",
        "            ```python\n",
        "            {text_to_nx_final}\n",
        "            ```\n",
        "\n",
        "            But I got this error: {error_message}\n",
        "\n",
        "            Please fix the code. Remember:\n",
        "            1. The graph is called G_adb\n",
        "            2. Only use networkx (as nx) and base Python libraries\n",
        "            3. The final answer should be stored in a variable called FINAL_RESULT\n",
        "            4. Only provide executable Python code, no explanations\n",
        "\n",
        "            Your corrected code:\n",
        "            \"\"\"\n",
        "\n",
        "            try:\n",
        "                fixed_code_response = llm.invoke(correction_prompt).content\n",
        "                # Clean up the response in case it returns markdown code blocks\n",
        "                text_to_nx_final = re.sub(r\"^```python\\n|```$\", \"\", fixed_code_response, flags=re.MULTILINE).strip()\n",
        "\n",
        "                print('-'*10)\n",
        "                print(\"FIXED CODE ATTEMPT:\")\n",
        "                print(text_to_nx_final)\n",
        "                print('-'*10)\n",
        "            except Exception as llm_error:\n",
        "                print(f\"Error requesting code correction: {llm_error}\")\n",
        "                return f\"Failed to get code correction: {llm_error}\"\n",
        "\n",
        "            attempt += 1\n",
        "\n",
        "    # If we exited the loop without a successful execution\n",
        "    if attempt > MAX_ATTEMPTS:\n",
        "        return f\"All {MAX_ATTEMPTS} attempts failed. Could not execute the NetworkX algorithm.\"\n",
        "\n",
        "    print('-'*10)\n",
        "    if \"FINAL_RESULT\" not in local_vars:\n",
        "        return \"Execution succeeded but FINAL_RESULT variable was not set.\"\n",
        "\n",
        "    FINAL_RESULT = local_vars[\"FINAL_RESULT\"]\n",
        "    print(f\"FINAL_RESULT: {FINAL_RESULT}\")\n",
        "    print('-'*10)\n",
        "\n",
        "    ######################\n",
        "\n",
        "    print(\"3) Formulating final answer\")\n",
        "\n",
        "    nx_to_text = llm.invoke(f\"\"\"\n",
        "        I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "        I have the following graph analysis query: {query}.\n",
        "\n",
        "        I have executed the following python code to help me answer my query:\n",
        "\n",
        "        ---\n",
        "        {text_to_nx_final}\n",
        "        ---\n",
        "\n",
        "        The `FINAL_RESULT` variable is set to the following: {FINAL_RESULT}.\n",
        "\n",
        "        Based on my original Query and FINAL_RESULT, generate a short and concise response to\n",
        "        answer my query.\n",
        "\n",
        "        Your response:\n",
        "    \"\"\").content\n",
        "\n",
        "    return nx_to_text\n",
        "\n",
        "network_tools = [text_to_nx_algorithm_to_text,transfer_to_profiling_expert, transfer_to_reporting_expert]"
      ],
      "metadata": {
        "id": "EeOqm_PS-KEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def network_expert(state:MessagesState)->Command[Literal[\"profile_expert\", \"reporting_expert\",\"network_expert\", \"visualize_network\",\"__end__\"]]:\n",
        "    system_prompt = (\n",
        "        \"\"\"\n",
        "        You expert for crime reporting tool called SHERLOCK ( Strategic Heuristic Engine for Research, Linking & Operational Crime Knowledge )\n",
        "        Your task is to Analyze networks using the text_to_nx_algorithm_to_text tool and if question reequires futher analysis transfer. When necessary to view subgraph of the data tranfer to visualize_network after analysis.\n",
        "\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
        "\n",
        "    ai_msg = model.bind_tools(network_tools).invoke(messages)\n",
        "\n",
        "    if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get(\"name\") == \"transfer_to_profiling_expert\":\n",
        "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
        "        tool_msg = {\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": \"Successfully transferred\",\n",
        "            \"tool_call_id\": tool_call_id,\n",
        "        }\n",
        "\n",
        "        return Command(\n",
        "            goto=\"profile_expert\", update={\"messages\": [ai_msg, tool_msg]}\n",
        "        )\n",
        "\n",
        "\n",
        "    if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get(\"name\") == \"transfer_to_reporting_expert\":\n",
        "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
        "\n",
        "        tool_msg = {\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": \"Successfully transferred\",\n",
        "            \"tool_call_id\": tool_call_id,\n",
        "        }\n",
        "\n",
        "        return Command(\n",
        "            goto=\"reporting_expert\", update={\"messages\": [ai_msg, tool_msg]}\n",
        "        )\n",
        "\n",
        "    if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get(\"name\") == \"text_to_nx_algorithm_to_text\":\n",
        "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
        "\n",
        "        content = text_to_nx_algorithm_to_text(ai_msg.tool_calls[-1].get(\"args\").get(\"query\"))\n",
        "        tool_msg = {\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": content,\n",
        "            \"tool_call_id\": tool_call_id,\n",
        "        }\n",
        "\n",
        "        return Command(\n",
        "            goto=\"network_expert\", update={\"messages\":[ai_msg, tool_msg]}\n",
        "        )\n",
        "\n",
        "    if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get(\"name\") == \"transfer_to_network_visualization\":\n",
        "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
        "        tool_msg = {\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": \"Successfully transferred\",\n",
        "            \"tool_call_id\": tool_call_id,\n",
        "        }\n",
        "        return Command(\n",
        "            goto=\"visualize_network\", update={\"messages\": [ai_msg, tool_msg]}\n",
        "        )\n",
        "\n",
        "    return {\"messages\": [ai_msg]}"
      ],
      "metadata": {
        "id": "MRkx0FYQDNPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "@tool\n",
        "def text_to_aql_to_text(query: str):\n",
        "    \"\"\"This tool is available to invoke the\n",
        "    ArangoGraphQAChain object, which enables you to\n",
        "    translate a Natural Language Query into AQL, execute\n",
        "    the query, and translate the result back into Natural Language.\n",
        "    \"\"\"\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "    chain = ArangoGraphQAChain.from_llm(\n",
        "    \tllm=llm,\n",
        "    \tgraph=arango_graph,\n",
        "    \tverbose=True,\n",
        "      allow_dangerous_requests=True,\n",
        "      return_aql_query=True\n",
        "    )\n",
        "\n",
        "    result = chain.invoke(query)\n",
        "\n",
        "    return str(result[\"result\"])\n",
        "\n",
        "profile_expert_tools = [text_to_aql_to_text, transfer_to_reporting_expert]"
      ],
      "metadata": {
        "id": "v4kSspXhdH40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def profile_expert(state:MessagesState)->Command[Literal[\"profile_expert\",\"reporting_expert\", \"visualize_network\",\"__end__\"]]:\n",
        "  system_prompt = (\n",
        "      f\"\"\"\n",
        "        You are an expert for crime reporting tool called SHERLOCK ( Strategic Heuristic Engine for Research, Linking & Operational Crime Knowledge )\n",
        "        Your task is to the arango database use arango database to analyze and answer questions about crime using the tools provided and transfer when neccesary.\n",
        "        When necessary to view subgraph of the data tranfer to visualize_network after analysis.\n",
        "\n",
        "      \"\"\"\n",
        "  )\n",
        "\n",
        "  ai_msg = model.bind_tools(profile_expert_tools).invoke([{\"role\":\"system\", \"content\":system_prompt}]+state[\"messages\"])\n",
        "\n",
        "  if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get(\"name\") == \"transfer_to_reporting_expert\":\n",
        "      tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
        "      tool_msg = {\n",
        "          \"role\": \"tool\",\n",
        "          \"content\": \"Successfully transferred\",\n",
        "          \"tool_call_id\": tool_call_id,\n",
        "      }\n",
        "      return Command(\n",
        "          goto=\"reporting_expert\", update={\"messages\": [ai_msg, tool_msg]}\n",
        "      )\n",
        "\n",
        "  if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get(\"name\") == \"text_to_aql_to_text\":\n",
        "      tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
        "      content = text_to_aql_to_text(ai_msg.tool_calls[-1].get(\"args\").get(\"query\"))\n",
        "      tool_msg = {\n",
        "          \"role\": \"tool\",\n",
        "          \"content\": content,\n",
        "          \"tool_call_id\": tool_call_id,\n",
        "      }\n",
        "\n",
        "      return Command(\n",
        "          goto=\"profile_expert\", update={\"messages\":[ai_msg, tool_msg]}\n",
        "      )\n",
        "\n",
        "  if len(ai_msg.tool_calls) > 0 and ai_msg.tool_calls[-1].get(\"name\") == \"transfer_to_network_visualization\":\n",
        "      tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
        "      tool_msg = {\n",
        "          \"role\": \"tool\",\n",
        "          \"content\": \"Successfully transferred\",\n",
        "          \"tool_call_id\": tool_call_id,\n",
        "      }\n",
        "      return Command(\n",
        "          goto=\"visualize_network\", update={\"messages\": [ai_msg, tool_msg]}\n",
        "      )\n",
        "\n",
        "  return {\"messages\":state[\"messages\"]+ [{\"role\":\"ai\", \"content\":ai_msg.content}]}\n",
        "def reporting_expert(state:MessagesState)->Command[Literal[\"__end__\"]]:\n",
        "\n",
        "  system_prompt = (\n",
        "      \"\"\"\n",
        "        You are an expert in  crime reporting. Analyze our conversations and do a comprehensive report.\n",
        "\n",
        "        Here is the conversation so far:\n",
        "      \"\"\"\n",
        "  )\n",
        "\n",
        "  messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
        "\n",
        "  ai_msg = model.invoke(messages)\n",
        "  return {\"messages\": [ai_msg]}\n"
      ],
      "metadata": {
        "id": "TjhFTRCAIMJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_graph(state:MessagesState)->Command[Literal[\"__end__\"]]:\n",
        "\n",
        "  system_prompt = (\n",
        "      f\"\"\"\n",
        "        You are an expert creating AQL query that follows a specific format for returning results for visualization later.\n",
        "\n",
        "        Here is the arango schema {arango_graph.schema}\n",
        "        Alway follow the format for the return query: {GraphElements}\n",
        "\n",
        "      Guidelines for creating AQL:\n",
        "        - Think step by step\n",
        "        - Analyze user question and determine the best AQL query to answer the question.\n",
        "        - Rely on `ArangoDB Schema` and `AQL Query Examples` (if provided) to generate the query\n",
        "        - Rely on `ArangoDB Schema` and `AQL Query Examples` (if provided) to generate the query\n",
        "        - Begin the `AQL Query` by the `WITH` AQL keyword to specify all of the ArangoDB Collections required\n",
        "        - Use only the provided relationship types and properties in the `ArangoDB Schema` and any `AQL Query Examples` queries\n",
        "        - Always use the `LIKE` operator for string matching\n",
        "        - Structure the return value of the AQL Query in the a way that is easy to read and understand and answer the user's question  ,\n",
        "        - Identify nodes and edges that might be relevant to the  question and include them in the AQL Query.\n",
        "\n",
        "        Your query:\n",
        "      \"\"\"\n",
        "  )\n",
        "\n",
        "  ai_msg = model.invoke([{\"role\":\"system\", \"content\":system_prompt}]+state[\"messages\"])\n",
        "\n",
        "  result = arango_graph.query(ai_msg.content)\n",
        "  data = GraphElements(nodes=result[\"nodes\"], edges=result[\"edges\"])\n",
        "  return {\"visualization_data\": visualize_graph}"
      ],
      "metadata": {
        "id": "Y-VSkME0pggz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class State(MessagesState):\n",
        "  visualization_data:GraphElements\n",
        "\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "\n",
        "workflow.add_node(\"supervisor\", supervisor)\n",
        "workflow.add_node(\"network_expert\", network_expert)\n",
        "workflow.add_node(\"profile_expert\", profile_expert)\n",
        "workflow.add_node(\"reporting_expert\", reporting_expert)\n",
        "workflow.add_node(\"visualize_network\", visualize_graph)\n",
        "\n",
        "workflow.add_edge(START, \"supervisor\")\n",
        "\n",
        "checkpointer=MemorySaver()\n",
        "\n",
        "graph = workflow.compile()"
      ],
      "metadata": {
        "id": "BWQH8t1DGnhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import convert_to_messages\n",
        "\n",
        "\n",
        "def pretty_print_messages(update):\n",
        "    if isinstance(update, tuple):\n",
        "        ns, update = update\n",
        "        # skip parent graph updates in the printouts\n",
        "        if len(ns) == 0:\n",
        "            return\n",
        "\n",
        "        graph_id = ns[-1].split(\":\")[0]\n",
        "        print(f\"Update from subgraph {graph_id}:\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "    for node_name, node_update in update.items():\n",
        "        print(f\"Update from node {node_name}:\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "        for m in convert_to_messages(node_update[\"messages\"]):\n",
        "            m.pretty_print()\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "8ISvDHIjSW36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in graph.stream(\n",
        "    {\"messages\": [(\"human\", \"Are there demographic patterns among victims of specific crime types? do a visualization\")]},\n",
        "):\n",
        "    pretty_print_messages(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XzfUHdOfJAbk",
        "outputId": "e8adb02d-0839-4393-e1c9-5ccbd1043b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update from node supervisor:\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': 'I can help you analyze demographic patterns among victims of specific crime types. This type of analysis falls under our profiling expertise, which examines demographic patterns and victimology across different crime categories.\\n\\nLet me transfer your request to our profiling expert who can provide this analysis and create visualizations of the demographic patterns:', 'type': 'text'}, {'id': 'toolu_01Pwpo3PjkqA9LNh6Ub9DQNz', 'input': {}, 'name': 'transfer_to_profiling_expert', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  transfer_to_profiling_expert (toolu_01Pwpo3PjkqA9LNh6Ub9DQNz)\n",
            " Call ID: toolu_01Pwpo3PjkqA9LNh6Ub9DQNz\n",
            "  Args:\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "Successfully transferred\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
            "WITH Crime, Person, CrimeType, CLASSIFIED_AS, INVOLVED\n",
            "FOR crime IN Crime\n",
            "    FOR involved IN INVOLVED\n",
            "        FILTER involved._from == crime._id\n",
            "        FOR person IN Person\n",
            "            FILTER person._id == involved._to\n",
            "            FOR classified IN CLASSIFIED_AS\n",
            "                FILTER classified._from == crime._id\n",
            "                FOR crimeType IN CrimeType\n",
            "                    FILTER crimeType._id == classified._to\n",
            "                    COLLECT crimeTypeDescription = crimeType.description, age = person.age, gender = person.gender, race = person.race INTO group\n",
            "                    RETURN {\n",
            "                        crimeType: crimeTypeDescription,\n",
            "                        demographics: {\n",
            "                            age: age,\n",
            "                            gender: gender,\n",
            "                            race: race,\n",
            "                            count: LENGTH(group)\n",
            "                        }\n",
            "                    }\n",
            "\u001b[0m\n",
            "AQL Result:\n",
            "\u001b[32;1m\u001b[1;3m[{'crimeType': 'AGG. ASSAULT', 'demographics': {'age': 0, 'gender': 'F', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 6}}, {'crimeType': 'AGG. ASSAULT', 'demographics': {'age': 0, 'gender': 'M', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 6}}, {'crimeType': 'AGG. ASSAULT', 'demographics': {'age': 1, 'gender': 'F', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 4}}, {'crimeType': 'AGG. ASSAULT', 'demographics': {'age': 1, 'gender': 'M', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 3}}, {'crimeType': 'AGG. ASSAULT', 'demographics': {'age': 1, 'gender': 'M', 'race': 'WHITE', 'count': 1}}, {'crimeType': 'AGG. ASSAULT', 'demographics': {'age': 2, 'gender': 'F', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 7}}, {'crimeType': 'AGG. ASSAULT', 'demographics': {'age': 2, 'gender': 'F', 'race': 'Unknown', 'count': 1}}, {'crimeType': 'AGG. ASSAULT', 'demographics': {'age': 2, 'gender': 'M', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 3}}, {'crimeType': 'AGG. ASSAULT', 'demographics': {'age': 3, 'gender': 'F', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 3}}, {'crimeType': 'AGG. ASSAULT', 'demographics': {'age': 3, 'gender': 'F', 'race': 'Unknown', 'count': 2}}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Update from node profile_expert:\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': \"I apologize for the confusion. I see that we don't have a dedicated profiling expert tool available in this system. Instead, I'll use the text-to-AQL tool to analyze demographic patterns among crime victims and then recommend visualization options.\", 'type': 'text'}, {'id': 'toolu_0115YaQZ4T1d3xykXnN8UZk7', 'input': {'query': 'What are the demographic patterns among victims of different crime types? Please provide a breakdown of victim demographics (age, gender, race) across different types of crimes.'}, 'name': 'text_to_aql_to_text', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  text_to_aql_to_text (toolu_0115YaQZ4T1d3xykXnN8UZk7)\n",
            " Call ID: toolu_0115YaQZ4T1d3xykXnN8UZk7\n",
            "  Args:\n",
            "    query: What are the demographic patterns among victims of different crime types? Please provide a breakdown of victim demographics (age, gender, race) across different types of crimes.\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "The analysis of demographic patterns among victims of different crime types reveals the following insights for the crime type \"AGG. ASSAULT\":\n",
            "\n",
            "1. **Age 0**: \n",
            "   - Female victims who are Black or African American have a count of 6.\n",
            "   - Male victims who are Black or African American also have a count of 6.\n",
            "\n",
            "2. **Age 1**:\n",
            "   - Female victims who are Black or African American have a count of 4.\n",
            "   - Male victims who are Black or African American have a count of 3.\n",
            "   - Male victims who are White have a count of 1.\n",
            "\n",
            "3. **Age 2**:\n",
            "   - Female victims who are Black or African American have a count of 7.\n",
            "   - Female victims with an unknown race have a count of 1.\n",
            "   - Male victims who are Black or African American have a count of 3.\n",
            "\n",
            "4. **Age 3**:\n",
            "   - Female victims who are Black or African American have a count of 3.\n",
            "   - Female victims with an unknown race have a count of 2.\n",
            "\n",
            "This breakdown highlights that the majority of victims of aggravated assault are Black or African American, with a notable number of female victims across various age groups.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
            "WITH Crime, CrimeType, INVOLVED, Person\n",
            "FOR crime IN Crime\n",
            "    FOR classified IN CLASSIFIED_AS\n",
            "        FILTER classified._from == crime._id\n",
            "        FOR crimeType IN CrimeType\n",
            "            FILTER classified._to == crimeType._id\n",
            "            FILTER crimeType.description == \"ROBBERY\"\n",
            "            FOR involved IN INVOLVED\n",
            "                FILTER involved._from == crime._id\n",
            "                FOR person IN Person\n",
            "                    FILTER involved._to == person._id\n",
            "                    COLLECT age = person.age, gender = person.gender, race = person.race WITH COUNT INTO count\n",
            "                    RETURN { age, gender, race, count }\n",
            "\u001b[0m\n",
            "AQL Result:\n",
            "\u001b[32;1m\u001b[1;3m[{'age': 1, 'gender': 'M', 'race': 'NATIVE_HAWAIIAN_OR_OTHER_PACIFIC_ISLANDER', 'count': 1}, {'age': 1, 'gender': 'M', 'race': 'Unknown', 'count': 2}, {'age': 2, 'gender': 'M', 'race': 'NATIVE_HAWAIIAN_OR_OTHER_PACIFIC_ISLANDER', 'count': 1}, {'age': 2, 'gender': 'M', 'race': 'WHITE', 'count': 1}, {'age': 3, 'gender': 'M', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}, {'age': 4, 'gender': 'F', 'race': 'Unknown', 'count': 1}, {'age': 6, 'gender': 'F', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}, {'age': 7, 'gender': 'M', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}, {'age': 7, 'gender': 'M', 'race': 'NATIVE_HAWAIIAN_OR_OTHER_PACIFIC_ISLANDER', 'count': 1}, {'age': 7, 'gender': 'M', 'race': 'WHITE', 'count': 1}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Update from node profile_expert:\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': \"Thank you for your query about demographic patterns among victims of specific crime types. I've analyzed our database and can provide you with insights on demographic patterns for victims of aggravated assault.\\n\\n## Key Findings for Aggravated Assault Victims:\\n\\n### Age 0 Group:\\n- **Female victims**: 6 Black or African American \\n- **Male victims**: 6 Black or African American\\n\\n### Age 1 Group:\\n- **Female victims**: 4 Black or African American\\n- **Male victims**: 3 Black or African American, 1 White\\n\\n### Age 2 Group:\\n- **Female victims**: 7 Black or African American, 1 Unknown race\\n- **Male victims**: 3 Black or African American\\n\\n### Age 3 Group:\\n- **Female victims**: 3 Black or African American, 2 Unknown race\\n\\n## Analysis:\\n- Black or African American individuals appear to be disproportionately victimized in aggravated assault cases\\n- There's a fairly even distribution between male and female victims in the youngest age group\\n- Female victims outnumber male victims in the older age categories\\n- Only 1 White victim appears in the data, specifically a male in Age group 1\\n\\nLet me examine other crime types to provide a more comprehensive analysis:\", 'type': 'text'}, {'id': 'toolu_017tSsN3QYJ9xMdXXFHHsBEt', 'input': {'query': 'What are the demographic patterns among victims of robbery? Please provide a breakdown by age, gender, and race.'}, 'name': 'text_to_aql_to_text', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  text_to_aql_to_text (toolu_017tSsN3QYJ9xMdXXFHHsBEt)\n",
            " Call ID: toolu_017tSsN3QYJ9xMdXXFHHsBEt\n",
            "  Args:\n",
            "    query: What are the demographic patterns among victims of robbery? Please provide a breakdown by age, gender, and race.\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "The demographic patterns among victims of robbery reveal a diverse range of ages, genders, and races. The data shows that male victims are more prevalent across various age groups. Specifically, there are male victims aged 1 and 2 who are identified as Native Hawaiian or Other Pacific Islander, with counts of 1 each. Additionally, there are male victims aged 1 and 2 with unknown and white racial backgrounds, respectively, with counts of 2 and 1. At age 3, there is one male victim identified as Black or African American. Female victims appear less frequently, with one female aged 4 of unknown race and one female aged 6 identified as Black or African American, each with a count of 1. Among 7-year-olds, there are male victims from Black or African American, Native Hawaiian or Other Pacific Islander, and white racial backgrounds, each with a count of 1. This breakdown highlights the varied demographic characteristics of robbery victims in the dataset.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
            "WITH Crime, CrimeType, Person, CLASSIFIED_AS, INVOLVED\n",
            "FOR crime IN Crime\n",
            "    FOR classified IN CLASSIFIED_AS\n",
            "        FILTER classified._from == crime._id\n",
            "        FOR crimeType IN CrimeType\n",
            "            FILTER classified._to == crimeType._id\n",
            "            FILTER crimeType.description IN [\"SEXUAL ASSAULT\", \"RAPE\"]\n",
            "            FOR involved IN INVOLVED\n",
            "                FILTER involved._from == crime._id\n",
            "                FOR person IN Person\n",
            "                    FILTER involved._to == person._id\n",
            "                    COLLECT age = person.age, gender = person.gender, race = person.race WITH COUNT INTO count\n",
            "                    RETURN { age, gender, race, count }\n",
            "\u001b[0m\n",
            "AQL Result:\n",
            "\u001b[32;1m\u001b[1;3m[{'age': 5, 'gender': 'F', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}, {'age': 5, 'gender': 'F', 'race': 'UNKNOWN', 'count': 1}, {'age': 5, 'gender': 'F', 'race': 'Unknown', 'count': 1}, {'age': 6, 'gender': 'F', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 2}, {'age': 6, 'gender': 'M', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}, {'age': 8, 'gender': 'F', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}, {'age': 9, 'gender': 'M', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}, {'age': 10, 'gender': 'M', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}, {'age': 11, 'gender': 'F', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}, {'age': 11, 'gender': 'F', 'race': 'WHITE', 'count': 1}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Update from node profile_expert:\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': \"Now let's look at patterns for victims of sexual assault:\", 'type': 'text'}, {'id': 'toolu_01TL9Bjqc3ke8EUMxN9FAFSM', 'input': {'query': 'What are the demographic patterns among victims of sexual assault or rape? Please provide a breakdown by age, gender, and race.'}, 'name': 'text_to_aql_to_text', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  text_to_aql_to_text (toolu_01TL9Bjqc3ke8EUMxN9FAFSM)\n",
            " Call ID: toolu_01TL9Bjqc3ke8EUMxN9FAFSM\n",
            "  Args:\n",
            "    query: What are the demographic patterns among victims of sexual assault or rape? Please provide a breakdown by age, gender, and race.\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "The demographic patterns among victims of sexual assault or rape, based on the data provided, show the following breakdown by age, gender, and race:\n",
            "\n",
            "- Age 5: There are three female victims, with one identified as Black or African American, one as Unknown, and one with an unspecified race.\n",
            "- Age 6: There are three victims, two females identified as Black or African American and one male also identified as Black or African American.\n",
            "- Age 8: There is one female victim identified as Black or African American.\n",
            "- Age 9: There is one male victim identified as Black or African American.\n",
            "- Age 10: There is one male victim identified as Black or African American.\n",
            "- Age 11: There are two female victims, one identified as Black or African American and the other as White.\n",
            "\n",
            "This data indicates a higher prevalence of female victims, particularly among young children, with a significant number identified as Black or African American.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
            "WITH Crime, CrimeType, Person, CLASSIFIED_AS, INVOLVED\n",
            "FOR crime IN Crime\n",
            "    FOR classified IN CLASSIFIED_AS\n",
            "        FILTER classified._from == crime._id\n",
            "        FOR crimeType IN CrimeType\n",
            "            FILTER classified._to == crimeType._id\n",
            "            FILTER crimeType.description IN [\"HOMICIDE\", \"MURDER\"]\n",
            "            FOR involved IN INVOLVED\n",
            "                FILTER involved._from == crime._id\n",
            "                FOR person IN Person\n",
            "                    FILTER involved._to == person._id\n",
            "                    COLLECT age = person.age, gender = person.gender, race = person.race WITH COUNT INTO count\n",
            "                    RETURN { age, gender, race, count }\n",
            "\u001b[0m\n",
            "AQL Result:\n",
            "\u001b[32;1m\u001b[1;3m[{'age': 1, 'gender': 'F', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}, {'age': 1, 'gender': 'M', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 2}, {'age': 2, 'gender': 'F', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}, {'age': 2, 'gender': 'F', 'race': 'WHITE', 'count': 1}, {'age': 8, 'gender': 'M', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}, {'age': 12, 'gender': 'M', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}, {'age': 13, 'gender': 'F', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}, {'age': 15, 'gender': 'M', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}, {'age': 16, 'gender': 'M', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 5}, {'age': 17, 'gender': 'F', 'race': 'BLACK_OR_AFRICAN_AMERICAN', 'count': 1}]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-334-ae87ebbdd0bc>\", line 1, in <cell line: 0>\n",
            "    for chunk in graph.stream(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\", line 2024, in stream\n",
            "    for _ in runner.tick(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
            "    run_with_retry(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
            "    return task.proc.invoke(task.input, config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
            "    input = step.invoke(input, config, **kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
            "    ret = context.run(self.func, *args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-322-d8e8c632e221>\", line 26, in profile_expert\n",
            "    content = text_to_aql_to_text(ai_msg.tool_calls[-1].get(\"args\").get(\"query\"))\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\", line 181, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\", line 889, in __call__\n",
            "    return self.run(tool_input, callbacks=callbacks)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\", line 763, in run\n",
            "    raise error_to_raise\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\", line 732, in run\n",
            "    response = context.run(self._run, *tool_args, **tool_kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/structured.py\", line 89, in _run\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-302-106adc7927e7>\", line 21, in text_to_aql_to_text\n",
            "    result = chain.invoke(query)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_community/chains/graph_qa/arangodb.py\", line 253, in _call\n",
            "    result = self.qa_chain(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\", line 181, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 843, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 683, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 908, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py\", line 823, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\", line 863, in create\n",
            "    return self._post(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1283, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 960, in request\n",
            "    return self._request(\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 996, in _request\n",
            "    response = self._client.send(\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 914, in send\n",
            "    response = self._send_handling_auth(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
            "    response = self._send_handling_redirects(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
            "    response = self._send_single_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
            "    response = transport.handle_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
            "    resp = self._pool.handle_request(req)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
            "    raise exc from None\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
            "    response = connection.handle_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
            "    return self._connection.handle_request(request)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\", line 136, in handle_request\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\", line 106, in handle_request\n",
            "    ) = self._receive_response_headers(**kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\", line 177, in _receive_response_headers\n",
            "    event = self._receive_event(timeout=timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\", line 217, in _receive_event\n",
            "    data = self._network_stream.read(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\", line 128, in read\n",
            "    return self._sock.recv(max_bytes)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ssl.py\", line 1295, in recv\n",
            "    return self.read(buflen)\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ssl.py\", line 1168, in read\n",
            "    return self._sslobj.read(len)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1684, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "               ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 948, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 988, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-334-ae87ebbdd0bc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m for chunk in graph.stream(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"human\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Are there demographic patterns among victims of specific crime types? do a visualization\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m ):\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2023\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2025\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-322-d8e8c632e221>\u001b[0m in \u001b[0;36mprofile_expert\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mtool_call_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mai_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_to_aql_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mai_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       tool_msg = {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tool_input, callbacks)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;34m\"\"\"Make tool callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_to_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_to_raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mtool_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtool_kwargs\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mconfig_param\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"content_and_artifact\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/structured.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, config, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_param\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"StructuredTool does not support sync invocation.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-302-106adc7927e7>\u001b[0m in \u001b[0;36mtext_to_aql_to_text\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m             outputs = (\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/chains/graph_qa/arangodb.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# Interpret AQL Result #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         result = self.qa_chain(\n\u001b[0m\u001b[1;32m    254\u001b[0m             {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    390\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m             outputs = (\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    125\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    139\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    682\u001b[0m                 results.append(\n\u001b[0;32m--> 683\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    684\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    909\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         )\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    997\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1294\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1295\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in graph.stream(\n",
        "    {\"messages\": [(\"human\", \"Are there demographic patterns among victims of specific crime types?\")]},\n",
        "      stream_mode=[\"updates\", \"messages\"]\n",
        "    ):\n",
        "    print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qgNQkY7nAi8W",
        "outputId": "53e1e253-b83a-4f39-9d39-2cf1d1499a44"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('messages', (AIMessageChunk(content=[], additional_kwargs={}, response_metadata={'model_name': 'claude-3-7-sonnet-20250219'}, id='run-d7a0848e-6bdf-4fd1-842f-45f10e445aad', usage_metadata={'input_tokens': 558, 'output_tokens': 1, 'total_tokens': 559, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), {'langgraph_step': 1, 'langgraph_node': 'supervisor', 'langgraph_triggers': ['start:supervisor'], 'langgraph_path': ('__pregel_pull', 'supervisor'), 'langgraph_checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'text': 'To', 'type': 'text', 'index': 0}], additional_kwargs={}, response_metadata={}, id='run-d7a0848e-6bdf-4fd1-842f-45f10e445aad'), {'langgraph_step': 1, 'langgraph_node': 'supervisor', 'langgraph_triggers': ['start:supervisor'], 'langgraph_path': ('__pregel_pull', 'supervisor'), 'langgraph_checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'text': ' analyze demographic patterns among victims of specific crime types,', 'type': 'text', 'index': 0}], additional_kwargs={}, response_metadata={}, id='run-d7a0848e-6bdf-4fd1-842f-45f10e445aad'), {'langgraph_step': 1, 'langgraph_node': 'supervisor', 'langgraph_triggers': ['start:supervisor'], 'langgraph_path': ('__pregel_pull', 'supervisor'), 'langgraph_checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'text': ' I can help by connecting you with our profiling expert', 'type': 'text', 'index': 0}], additional_kwargs={}, response_metadata={}, id='run-d7a0848e-6bdf-4fd1-842f-45f10e445aad'), {'langgraph_step': 1, 'langgraph_node': 'supervisor', 'langgraph_triggers': ['start:supervisor'], 'langgraph_path': ('__pregel_pull', 'supervisor'), 'langgraph_checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'text': ' who specializes in demographic analysis of crime data', 'type': 'text', 'index': 0}], additional_kwargs={}, response_metadata={}, id='run-d7a0848e-6bdf-4fd1-842f-45f10e445aad'), {'langgraph_step': 1, 'langgraph_node': 'supervisor', 'langgraph_triggers': ['start:supervisor'], 'langgraph_path': ('__pregel_pull', 'supervisor'), 'langgraph_checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'text': '.', 'type': 'text', 'index': 0}], additional_kwargs={}, response_metadata={}, id='run-d7a0848e-6bdf-4fd1-842f-45f10e445aad'), {'langgraph_step': 1, 'langgraph_node': 'supervisor', 'langgraph_triggers': ['start:supervisor'], 'langgraph_path': ('__pregel_pull', 'supervisor'), 'langgraph_checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'id': 'toolu_01UcL7boNBuiAfRxuSNc7j82', 'input': {}, 'name': 'transfer_to_profiling_expert', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-d7a0848e-6bdf-4fd1-842f-45f10e445aad', tool_calls=[{'name': 'transfer_to_profiling_expert', 'args': {}, 'id': 'toolu_01UcL7boNBuiAfRxuSNc7j82', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'transfer_to_profiling_expert', 'args': '', 'id': 'toolu_01UcL7boNBuiAfRxuSNc7j82', 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 1, 'langgraph_node': 'supervisor', 'langgraph_triggers': ['start:supervisor'], 'langgraph_path': ('__pregel_pull', 'supervisor'), 'langgraph_checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': '', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-d7a0848e-6bdf-4fd1-842f-45f10e445aad', tool_calls=[{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}], tool_call_chunks=[{'name': None, 'args': '', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 1, 'langgraph_node': 'supervisor', 'langgraph_triggers': ['start:supervisor'], 'langgraph_path': ('__pregel_pull', 'supervisor'), 'langgraph_checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content='', additional_kwargs={}, response_metadata={'stop_reason': 'tool_use', 'stop_sequence': None}, id='run-d7a0848e-6bdf-4fd1-842f-45f10e445aad', usage_metadata={'input_tokens': 0, 'output_tokens': 74, 'total_tokens': 74, 'input_token_details': {}}), {'langgraph_step': 1, 'langgraph_node': 'supervisor', 'langgraph_triggers': ['start:supervisor'], 'langgraph_path': ('__pregel_pull', 'supervisor'), 'langgraph_checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'checkpoint_ns': 'supervisor:a296f176-eda2-841e-f840-c2c8e4c37b4b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('updates', {'supervisor': {'messages': [AIMessage(content=[{'text': 'To analyze demographic patterns among victims of specific crime types, I can help by connecting you with our profiling expert who specializes in demographic analysis of crime data.', 'type': 'text', 'index': 0}, {'id': 'toolu_01UcL7boNBuiAfRxuSNc7j82', 'input': {}, 'name': 'transfer_to_profiling_expert', 'type': 'tool_use', 'index': 1, 'partial_json': ''}], additional_kwargs={}, response_metadata={'model_name': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None}, id='run-d7a0848e-6bdf-4fd1-842f-45f10e445aad', tool_calls=[{'name': 'transfer_to_profiling_expert', 'args': {}, 'id': 'toolu_01UcL7boNBuiAfRxuSNc7j82', 'type': 'tool_call'}], usage_metadata={'input_tokens': 558, 'output_tokens': 75, 'total_tokens': 633, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), {'role': 'tool', 'content': 'Successfully transferred', 'tool_call_id': 'toolu_01UcL7boNBuiAfRxuSNc7j82'}]}})\n",
            "('messages', (AIMessageChunk(content=[], additional_kwargs={}, response_metadata={'model_name': 'claude-3-7-sonnet-20250219'}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', usage_metadata={'input_tokens': 664, 'output_tokens': 3, 'total_tokens': 667, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'text': \"I'll\", 'type': 'text', 'index': 0}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb'), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'text': ' use our database to analyze demographic patterns among victims of', 'type': 'text', 'index': 0}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb'), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'text': ' specific crime types. Let me query the information', 'type': 'text', 'index': 0}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb'), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'text': ' for you.', 'type': 'text', 'index': 0}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb'), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'id': 'toolu_016Vz695n15Bzoz4umRCybFy', 'input': {}, 'name': 'text_to_aql_to_text', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', tool_calls=[{'name': 'text_to_aql_to_text', 'args': {}, 'id': 'toolu_016Vz695n15Bzoz4umRCybFy', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'text_to_aql_to_text', 'args': '', 'id': 'toolu_016Vz695n15Bzoz4umRCybFy', 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': '', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', tool_calls=[{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}], tool_call_chunks=[{'name': None, 'args': '', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': '{\"query\": \"', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', tool_calls=[{'name': '', 'args': {'query': ''}, 'id': None, 'type': 'tool_call'}], tool_call_chunks=[{'name': None, 'args': '{\"query\": \"', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'What a', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'What a', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'What a', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 're ', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 're ', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 're ', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'the demograp', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'the demograp', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'the demograp', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'hic', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'hic', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'hic', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': ' pattern', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': ' pattern', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': ' pattern', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 's amon', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 's amon', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 's amon', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'g ', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'g ', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'g ', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'victims', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'victims', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'victims', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': ' of di', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': ' of di', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': ' of di', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'ffere', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'ffere', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'ffere', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'nt cri', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'nt cri', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'nt cri', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'me types? Pl', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'me types? Pl', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'me types? Pl', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'ease a', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'ease a', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'ease a', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'na', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'na', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'na', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'lyze vi', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'lyze vi', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'lyze vi', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'ctim d', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'ctim d', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'ctim d', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'emogra', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'emogra', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'emogra', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'phics l', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'phics l', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'phics l', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'ike ag', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'ike ag', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'ike ag', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'e,', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'e,', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'e,', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': ' gend', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': ' gend', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': ' gend', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'er, rac', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'er, rac', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'er, rac', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'e,', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'e,', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'e,', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': ' or so', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': ' or so', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': ' or so', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'cioeconom', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'cioeconom', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'cioeconom', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'ic fa', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'ic fa', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'ic fa', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'ctors ac', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'ctors ac', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'ctors ac', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'ross ', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'ross ', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'ross ', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'different ', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'different ', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'different ', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 'categorie', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 'categorie', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 'categorie', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': 's of crimes', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': 's of crimes', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': 's of crimes', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content=[{'partial_json': '.\"}', 'type': 'tool_use', 'index': 1}], additional_kwargs={}, response_metadata={}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', invalid_tool_calls=[{'name': None, 'args': '.\"}', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], tool_call_chunks=[{'name': None, 'args': '.\"}', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "('messages', (AIMessageChunk(content='', additional_kwargs={}, response_metadata={'stop_reason': 'tool_use', 'stop_sequence': None}, id='run-5fffbd4f-13c4-44bc-855b-f625c7ec13bb', usage_metadata={'input_tokens': 0, 'output_tokens': 119, 'total_tokens': 119, 'input_token_details': {}}), {'langgraph_step': 2, 'langgraph_node': 'profile_expert', 'langgraph_triggers': ['branch:supervisor:__self__:profile_expert'], 'langgraph_path': ('__pregel_pull', 'profile_expert'), 'langgraph_checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'checkpoint_ns': 'profile_expert:ee08bcd1-a81a-9027-7029-b31b2ffd4f9b', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-7-sonnet-latest', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}))\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
            "WITH Crime, Person, CrimeType, CLASSIFIED_AS, INVOLVED\n",
            "FOR crime IN Crime\n",
            "    FOR involved IN INVOLVED\n",
            "        FILTER involved._from == crime._id\n",
            "        FOR person IN Person\n",
            "            FILTER person._id == involved._to\n",
            "            FOR classified IN CLASSIFIED_AS\n",
            "                FILTER classified._from == crime._id\n",
            "                FOR crimeType IN CrimeType\n",
            "                    FILTER crimeType._id == classified._to\n",
            "                    COLLECT crimeTypeDescription = crimeType.description INTO demographics = {\n",
            "                        age: person.age,\n",
            "                        gender: person.gender,\n",
            "                        race: person.race,\n",
            "                        ethnicity: person.ethnicity\n",
            "                    }\n",
            "                    RETURN {\n",
            "                        crimeType: crimeTypeDescription,\n",
            "                        demographics: demographics\n",
            "                    }\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ReadTimeout",
          "evalue": "HTTPSConnectionPool(host='d6b0bbc5c6ad.arangodb.cloud', port=8529): Read timed out. (read timeout=60)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    842\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/util.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketTimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             raise ReadTimeoutError(\n\u001b[0m\u001b[1;32m    368\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Read timed out. (read timeout={timeout_value})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='d6b0bbc5c6ad.arangodb.cloud', port=8529): Read timed out. (read timeout=60)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-7074fbbb5cb2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m for chunk in graph.stream(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"human\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Are there demographic patterns among victims of specific crime types?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0mstream_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"updates\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     ):\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2022\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2025\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# panic on failure or timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         _panic_or_proceed(\n\u001b[0m\u001b[1;32m    303\u001b[0m             \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpanic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36m_panic_or_proceed\u001b[0;34m(futs, timeout_exc_cls, panic)\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;31m# raise the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpanic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minflight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;31m# if we got here means we timed out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/executor.py\u001b[0m in \u001b[0;36mdone\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;34m\"\"\"Remove the task from the tasks dict when it's done.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGraphBubbleUp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;31m# This exception is an interruption signal, not an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m                 )\n\u001b[1;32m    545\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-d8e8c632e221>\u001b[0m in \u001b[0;36mprofile_expert\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mai_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mai_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text_to_aql_to_text\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mtool_call_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mai_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_to_aql_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mai_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       tool_msg = {\n\u001b[1;32m     28\u001b[0m           \u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"tool\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tool_input, callbacks)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;34m\"\"\"Make tool callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_to_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_to_raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconfig_param\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0m_get_runnable_config_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mtool_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtool_kwargs\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mconfig_param\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"content_and_artifact\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/structured.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, config, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconfig_param\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0m_get_runnable_config_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_param\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"StructuredTool does not support sync invocation.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-106adc7927e7>\u001b[0m in \u001b[0;36mtext_to_aql_to_text\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"result\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             outputs = (\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/chains/graph_qa/arangodb.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0maql_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maql_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAQLQueryExecuteError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0maql_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/graphs/arangodb_graph.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, top_k, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/arango/aql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, count, batch_size, ttl, bind_vars, full_count, max_plans, optimizer_rules, cache, memory_limit, fail_on_warning, profile, max_transaction_size, max_warning_count, intermediate_commit_count, intermediate_commit_size, satellite_sync_wait, stream, skip_inaccessible_cols, max_runtime, fill_block_cache, allow_dirty_read, allow_retry, force_one_shard_attribute_value, use_plan_cache)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_retry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_retry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/arango/api.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, request, response_handler)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAPI\u001b[0m \u001b[0mexecution\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \"\"\"\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/arango/executor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, request, response_handler)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAPI\u001b[0m \u001b[0mexecution\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/arango/connection.py\u001b[0m in \u001b[0;36msend_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \"\"\"\n\u001b[1;32m    310\u001b[0m         \u001b[0mhost_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_host_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/arango/connection.py\u001b[0m in \u001b[0;36mprocess_request\u001b[0;34m(self, host_index, request, auth)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mtries\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_tries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 resp = self._http.send_request(\n\u001b[0m\u001b[1;32m    157\u001b[0m                     \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sessions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhost_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/arango/http.py\u001b[0m in \u001b[0;36msend_request\u001b[0;34m(self, session, method, url, headers, params, data, auth)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marango\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \"\"\"\n\u001b[0;32m--> 230\u001b[0;31m         response = session.request(\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    711\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_InvalidHeader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='d6b0bbc5c6ad.arangodb.cloud', port=8529): Read timed out. (read timeout=60)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arango_graph.query(\"\"\"WITH Crime, CrimeType, Person, INVOLVED, CLASSIFIED_AS\n",
        "FOR crime IN Crime\n",
        "    FOR classified IN CLASSIFIED_AS\n",
        "        FILTER classified._from == crime._id\n",
        "        FOR crimeType IN CrimeType\n",
        "            FILTER classified._to == crimeType._id\n",
        "            FILTER crimeType.description == \"AUTO THEFT\"\n",
        "            FOR involved IN INVOLVED\n",
        "                FILTER involved._from == crime._id\n",
        "                FOR person IN Person\n",
        "                    FILTER involved._to == person._id\n",
        "                    COLLECT ageGroup = FLOOR(person.age / 10) * 10 INTO ageGroups\n",
        "                    RETURN { ageGroup: ageGroup, count: LENGTH(ageGroups) }\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwL_bBeVs4I8",
        "outputId": "deec9908-f9e6-40f5-f51c-6e7c4b9a8946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'ageGroup': 0, 'count': 350},\n",
              " {'ageGroup': 10, 'count': 39},\n",
              " {'ageGroup': 20, 'count': 1050},\n",
              " {'ageGroup': 30, 'count': 1263},\n",
              " {'ageGroup': 40, 'count': 770},\n",
              " {'ageGroup': 50, 'count': 629},\n",
              " {'ageGroup': 60, 'count': 505},\n",
              " {'ageGroup': 70, 'count': 203},\n",
              " {'ageGroup': 80, 'count': 66},\n",
              " {'ageGroup': 90, 'count': 5}]"
            ]
          },
          "metadata": {},
          "execution_count": 332
        }
      ]
    }
  ]
}